
# TÜBİTAK Project

This repository contains the source code and data related to a project developed under the scope of TÜBİTAK. The project focuses on analyzing datasets using machine learning techniques, particularly for classification problems between benign and malicious datasets. Below is a detailed explanation of the project.

## Table of Contents

1. [Project Overview](#project-overview)
2. [Technologies Used](#technologies-used)
3. [Installation Instructions](#installation-instructions)
4. [Dataset Information](#dataset-information)
5. [Model Training](#model-training)
6. [Results and Evaluation](#results-and-evaluation)
7. [Contributing](#contributing)
8. [License](#license)

## Project Overview

The project aims to develop a machine learning model that differentiates between benign and malicious data samples. The primary objective is to apply various preprocessing techniques, train models, and evaluate their performance using industry-standard metrics such as accuracy, precision, recall, and F1-score.

Key Features:
- Data preprocessing (normalization, missing value handling)
- Model selection and training (SVM, Random Forest, Neural Networks)
- Hyperparameter tuning
- Performance evaluation with detailed metrics

## Technologies Used

- **Python 3.x**: The primary programming language used for building the project.
- **TensorFlow/Keras**: Used for developing neural network models.
- **Scikit-learn**: Utilized for preprocessing and implementing classical machine learning algorithms.
- **Pandas and NumPy**: Data manipulation and numerical computations.
- **Matplotlib/Seaborn**: For data visualization and plotting graphs.

## Installation Instructions

Follow these steps to set up the project locally:

1. **Clone the repository**:
   ```bash
   git clone https://github.com/SedanurCeylan/tubitakprojesi.git
   cd tubitakprojesi
   ```

2. **Create a virtual environment** (optional but recommended):
   ```bash
   python -m venv env
   source env/bin/activate  # On Windows use `env\Scriptsctivate`
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Run the application**:
   The main script for data preprocessing and training the model is `main.py`. You can start it by running:
   ```bash
   python main.py
   ```

## Dataset Information

The project uses two main datasets:
1. **Benign Dataset**: Contains non-malicious, normal data samples used to train the model.
2. **Malicious Dataset**: Includes harmful or malicious samples that need to be detected by the model.

Both datasets are preprocessed to handle missing values, normalize the data, and split into training and testing sets.

## Model Training

The training process involves testing various machine learning models:
- **Support Vector Machine (SVM)**
- **Random Forest**
- **Convolutional Neural Networks (CNN)** (For complex data patterns)

Each model undergoes cross-validation to fine-tune hyperparameters, ensuring optimal performance.

## Results and Evaluation

The trained models are evaluated using the following metrics:
- **Accuracy**: The percentage of correctly predicted instances.
- **Precision and Recall**: To evaluate the quality of the classification, especially for imbalanced datasets.
- **F1-score**: A balanced measure between precision and recall.

Graphs and plots generated by the project can be found in the `results/` directory, providing a visual interpretation of the model performance.

## Contributing

Contributions to this project are welcome! If you would like to contribute:
1. Fork the repository.
2. Create a new branch (`git checkout -b feature-branch`).
3. Make your changes.
4. Submit a pull request.

For major changes, please open an issue first to discuss what you would like to change.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
